{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PJWSTK/s14028/Engine\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import scipy.io as mat\n",
    "\n",
    "from common import *\n",
    "from augmentation import add_pmap\n",
    "from augmentation import augmentation_data\n",
    "from augmentation import augment_data\n",
    "\n",
    "from CNN.CNN_v2_1 import CNN_v2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = mat.loadmat(\"mall_dataset/perspective_roi.mat\")[\"pMapN\"]\n",
    "\n",
    "perspective /= np.min(perspective)\n",
    "perspective = np.round(perspective).astype(np.uint8)\n",
    "\n",
    "train, test = data_sets()\n",
    "image_tensors = train[0], test[0]\n",
    "person_coo_tensors = train[1], test[1]\n",
    "count_matrix = train[2], test[2]\n",
    "\n",
    "image_train, image_test = image_tensors\n",
    "person_coo_train, person_coo_test = person_coo_tensors\n",
    "count_train, count_test = count_matrix\n",
    "count_train = count_train.astype(np.uint16)\n",
    "count_test = count_test.astype(np.uint16)\n",
    "\n",
    "image_train = add_pmap(image_train, perspective)\n",
    "image_test = add_pmap(image_test, perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f61f2ac7940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v2_1 = CNN_v2_1((480, 640, 4), split_into_parts=40)\n",
    "cnn_v2_1.def_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cnn_v2_1._prepare_images(image_train)\n",
    "anwsers = cnn_v2_1._prepare_anwsers(person_coo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_count = (np.sum(anwsers == 1) * 0.25).astype(np.uint32)\n",
    "zeros_count = (ones_count / 0.25 * 0.75).astype(np.uint32)\n",
    "validation_length = (zeros_count + ones_count).astype(np.int32)\n",
    "\n",
    "val_indices = np.concatenate([np.where(anwsers == 0)[0][:zeros_count],\n",
    "                              np.where(anwsers == 1)[0][:ones_count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = -(images.shape[0] - val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "augmentation = augmentation_data(image_train, anwsers, 40)\n",
    "augmented_data = augment_data(generator, augmentation, images, anwsers)\n",
    "images, anwsers = augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 1\n",
    "\n",
    "images[-validation_length:], images[val_indices] = images[val_indices], images[-validation_length:]\n",
    "anwsers[-validation_length:], anwsers[val_indices] = anwsers[val_indices], anwsers[-validation_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-61ecc98f7da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m parallel_model = keras.utils.multi_gpu_model(\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mcnn_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         cpu_merge=False)\n\u001b[1;32m      5\u001b[0m parallel_model.compile(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_v2' is not defined"
     ]
    }
   ],
   "source": [
    "parallel_model = keras.utils.multi_gpu_model(\n",
    "        cnn_v2_1.model,\n",
    "        gpus=2,\n",
    "        cpu_merge=False)\n",
    "parallel_model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=\"adam\", \n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save_weights(\"CNN/CNN_v2/weights/cnn_v2_40_1e_3_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights(\"CNN/CNN_v2/weights/cnn_v2_40_1e_3_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5311770 samples, validate on 51292 samples\n",
      "Epoch 1/10\n",
      "5311770/5311770 [==============================] - 129s 24us/step - loss: 0.2126 - acc: 0.9325 - val_loss: 0.5212 - val_acc: 0.8430\n",
      "Epoch 2/10\n",
      "5311770/5311770 [==============================] - 130s 25us/step - loss: 0.2074 - acc: 0.9346 - val_loss: 0.5308 - val_acc: 0.8227\n",
      "Epoch 3/10\n",
      "5311770/5311770 [==============================] - 129s 24us/step - loss: 0.2049 - acc: 0.9354 - val_loss: 0.5227 - val_acc: 0.7969\n",
      "Epoch 4/10\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.2002 - acc: 0.9373 - val_loss: 0.4927 - val_acc: 0.8515\n",
      "Epoch 5/10\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1960 - acc: 0.9387 - val_loss: 0.5361 - val_acc: 0.8216\n",
      "Epoch 6/10\n",
      "5311770/5311770 [==============================] - 129s 24us/step - loss: 0.1937 - acc: 0.9383 - val_loss: 0.4582 - val_acc: 0.8401\n",
      "Epoch 7/10\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1877 - acc: 0.9407 - val_loss: 0.4789 - val_acc: 0.8373\n",
      "Epoch 8/10\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1854 - acc: 0.9418 - val_loss: 0.5605 - val_acc: 0.7558\n",
      "Epoch 9/10\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1760 - acc: 0.9454 - val_loss: 0.4622 - val_acc: 0.8193\n",
      "Epoch 10/10\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1700 - acc: 0.9473 - val_loss: 0.5513 - val_acc: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b69995a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save_weights(\"CNN/CNN_v2/weights/cnn_v2_40_1e_3_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights(\"CNN/CNN_v2/weights/cnn_v2_40_1e_3_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_1:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5311770 samples, validate on 51292 samples\n",
      "Epoch 1/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1664 - acc: 0.9485 - val_loss: 0.5295 - val_acc: 0.8201\n",
      "Epoch 2/20\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1618 - acc: 0.9500 - val_loss: 0.5177 - val_acc: 0.8158\n",
      "Epoch 3/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1616 - acc: 0.9502 - val_loss: 0.4864 - val_acc: 0.8039\n",
      "Epoch 4/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1587 - acc: 0.9511 - val_loss: 0.5490 - val_acc: 0.7917\n",
      "Epoch 5/20\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1589 - acc: 0.9511 - val_loss: 0.5126 - val_acc: 0.7990\n",
      "Epoch 6/20\n",
      "5311770/5311770 [==============================] - 129s 24us/step - loss: 0.1514 - acc: 0.9539 - val_loss: 0.5076 - val_acc: 0.8356\n",
      "Epoch 7/20\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1476 - acc: 0.9553 - val_loss: 0.5079 - val_acc: 0.7914\n",
      "Epoch 8/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1416 - acc: 0.9575 - val_loss: 0.4526 - val_acc: 0.8400\n",
      "Epoch 9/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1381 - acc: 0.9587 - val_loss: 0.5073 - val_acc: 0.8143\n",
      "Epoch 10/20\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1363 - acc: 0.9594 - val_loss: 0.5421 - val_acc: 0.7764\n",
      "Epoch 11/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1479 - acc: 0.9544 - val_loss: 0.6550 - val_acc: 0.6832\n",
      "Epoch 12/20\n",
      "5311770/5311770 [==============================] - 127s 24us/step - loss: 0.1442 - acc: 0.9559 - val_loss: 0.5305 - val_acc: 0.7923\n",
      "Epoch 13/20\n",
      "5311770/5311770 [==============================] - 128s 24us/step - loss: 0.1300 - acc: 0.9613 - val_loss: 0.5569 - val_acc: 0.7883\n",
      "Epoch 14/20\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 0.1257 - acc: 0.9629 - val_loss: 0.5270 - val_acc: 0.7933\n",
      "Epoch 15/20\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 0.1231 - acc: 0.9638 - val_loss: 0.5428 - val_acc: 0.7630\n",
      "Epoch 16/20\n",
      "5311770/5311770 [==============================] - 131s 25us/step - loss: 0.1219 - acc: 0.9641 - val_loss: 0.5410 - val_acc: 0.7768\n",
      "Epoch 17/20\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 0.1168 - acc: 0.9658 - val_loss: 0.6236 - val_acc: 0.5682\n",
      "Epoch 18/20\n",
      "5311770/5311770 [==============================] - 130s 25us/step - loss: 0.1171 - acc: 0.9657 - val_loss: 0.6205 - val_acc: 0.7520\n",
      "Epoch 19/20\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 0.1150 - acc: 0.9663 - val_loss: 0.5118 - val_acc: 0.8010\n",
      "Epoch 20/20\n",
      "5311770/5311770 [==============================] - 131s 25us/step - loss: 0.1132 - acc: 0.9669 - val_loss: 0.5555 - val_acc: 0.7675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b69ee1278>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=20,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save_weights(\"CNN/CNN_v2/weights/cnn_v2_40_1e_5_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights(\"CNN/CNN_v2/weights/cnn_v2_40_1e_5_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"CNN/CNN_v2/weights/cnn_v2_40_1e_5_{epoch:02d}_{val_acc:.2f}\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                             monitor='val_acc',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=True,\n",
    "                                             mode='max')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5311770 samples, validate on 51292 samples\n",
      "Epoch 1/20\n",
      "5311770/5311770 [==============================] - 130s 25us/step - loss: 0.2239 - acc: 0.9212 - val_loss: 0.5870 - val_acc: 0.7548\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75480, saving model to CNN/CNN_v2/weights/cnn_v2_40_1e_5_01_0.75\n",
      "Epoch 2/20\n",
      "5311770/5311770 [==============================] - 130s 25us/step - loss: 0.1528 - acc: 0.9521 - val_loss: 0.4791 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75480 to 0.75719, saving model to CNN/CNN_v2/weights/cnn_v2_40_1e_5_02_0.76\n",
      "Epoch 3/20\n",
      "5311770/5311770 [==============================] - 130s 24us/step - loss: 0.1410 - acc: 0.9559 - val_loss: 0.5187 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.75719 to 0.79773, saving model to CNN/CNN_v2/weights/cnn_v2_40_1e_5_03_0.80\n",
      "Epoch 4/20\n",
      "5311770/5311770 [==============================] - 131s 25us/step - loss: 0.1333 - acc: 0.9586 - val_loss: 0.5202 - val_acc: 0.7550\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.79773\n",
      "Epoch 5/20\n",
      "5311770/5311770 [==============================] - 130s 25us/step - loss: 0.1298 - acc: 0.9598 - val_loss: 0.5410 - val_acc: 0.7508\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79773\n",
      "Epoch 6/20\n",
      "5311770/5311770 [==============================] - 131s 25us/step - loss: 0.1257 - acc: 0.9613 - val_loss: 0.5730 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79773\n",
      "Epoch 7/20\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 0.1241 - acc: 0.9619 - val_loss: 0.4857 - val_acc: 0.7559\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79773\n",
      "Epoch 8/20\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 0.1221 - acc: 0.9625 - val_loss: 0.4512 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79773\n",
      "Epoch 9/20\n",
      "1420000/5311770 [=======>......................] - ETA: 1:35 - loss: 0.1202 - acc: 0.9632"
     ]
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000,\n",
    "                   epochs=20, validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                  callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
