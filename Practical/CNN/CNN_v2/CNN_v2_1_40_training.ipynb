{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PJWSTK/s14028/Engine\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import scipy.io as mat\n",
    "\n",
    "from common import *\n",
    "from augmentation import add_pmap\n",
    "from augmentation import augmentation_data\n",
    "from augmentation import augment_data\n",
    "\n",
    "from CNN.CNN_v2_1 import CNN_v2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = mat.loadmat(\"mall_dataset/perspective_roi.mat\")[\"pMapN\"]\n",
    "\n",
    "perspective /= np.min(perspective)\n",
    "perspective = np.round(perspective).astype(np.uint8)\n",
    "\n",
    "train, test = data_sets()\n",
    "image_tensors = train[0], test[0]\n",
    "person_coo_tensors = train[1], test[1]\n",
    "count_matrix = train[2], test[2]\n",
    "\n",
    "image_train, image_test = image_tensors\n",
    "person_coo_train, person_coo_test = person_coo_tensors\n",
    "count_train, count_test = count_matrix\n",
    "count_train = count_train.astype(np.uint16)\n",
    "count_test = count_test.astype(np.uint16)\n",
    "\n",
    "image_train = add_pmap(image_train, perspective)\n",
    "image_test = add_pmap(image_test, perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f213afb19e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v2_1 = CNN_v2_1((480, 640, 4), split_into_parts=40)\n",
    "cnn_v2_1.def_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cnn_v2_1._prepare_images(image_train)\n",
    "anwsers = cnn_v2_1._prepare_anwsers(person_coo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_count = (np.sum(anwsers == 1) * 0.25).astype(np.uint32)\n",
    "zeros_count = (ones_count / 0.25 * 0.75).astype(np.uint32)\n",
    "validation_length = (zeros_count + ones_count).astype(np.int32)\n",
    "\n",
    "val_indices = np.concatenate([np.where(anwsers == 0)[0][:zeros_count],\n",
    "                              np.where(anwsers == 1)[0][:ones_count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = -(images.shape[0] - val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "augmentation = augmentation_data(image_train, anwsers, 40)\n",
    "augmented_data = augment_data(generator, augmentation, images, anwsers)\n",
    "images, anwsers = augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 1\n",
    "\n",
    "images[-validation_length:], images[val_indices] = images[val_indices], images[-validation_length:]\n",
    "anwsers[-validation_length:], anwsers[val_indices] = anwsers[val_indices], anwsers[-validation_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = keras.utils.multi_gpu_model(\n",
    "        cnn_v2_1.model,\n",
    "        gpus=2,\n",
    "        cpu_merge=False)\n",
    "parallel_model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=\"adam\", \n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5311770 samples, validate on 51292 samples\n",
      "Epoch 1/10\n",
      "5311770/5311770 [==============================] - 132s 25us/step - loss: 74.6552 - acc: 0.5125 - val_loss: 2.9013 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "5311770/5311770 [==============================] - 118s 22us/step - loss: 1.3929 - acc: 0.4935 - val_loss: 0.8473 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "5311770/5311770 [==============================] - 118s 22us/step - loss: 0.8496 - acc: 0.4929 - val_loss: 0.7603 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "5311770/5311770 [==============================] - 117s 22us/step - loss: 0.7892 - acc: 0.4929 - val_loss: 0.7342 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "5311770/5311770 [==============================] - 117s 22us/step - loss: 0.7697 - acc: 0.4929 - val_loss: 0.7193 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "5311770/5311770 [==============================] - 120s 23us/step - loss: 0.7594 - acc: 0.4929 - val_loss: 0.7126 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "5311770/5311770 [==============================] - 125s 24us/step - loss: 0.7534 - acc: 0.4929 - val_loss: 0.7076 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "5311770/5311770 [==============================] - 125s 24us/step - loss: 0.7496 - acc: 0.4929 - val_loss: 0.7034 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "5311770/5311770 [==============================] - 126s 24us/step - loss: 0.7472 - acc: 0.4929 - val_loss: 0.7028 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "5311770/5311770 [==============================] - 126s 24us/step - loss: 0.7464 - acc: 0.4929 - val_loss: 0.7069 - val_acc: 0.7499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fd018fd68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_1:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5311770 samples, validate on 51292 samples\n",
      "Epoch 1/10\n",
      "5311770/5311770 [==============================] - 123s 23us/step - loss: 0.7451 - acc: 0.4929 - val_loss: 0.7013 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "5311770/5311770 [==============================] - 123s 23us/step - loss: 0.7434 - acc: 0.4929 - val_loss: 0.6998 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "5311770/5311770 [==============================] - 122s 23us/step - loss: 0.7428 - acc: 0.4929 - val_loss: 0.6990 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7423 - acc: 0.4929 - val_loss: 0.6986 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7419 - acc: 0.4929 - val_loss: 0.6997 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "5311770/5311770 [==============================] - 125s 24us/step - loss: 0.7417 - acc: 0.4929 - val_loss: 0.6974 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "5311770/5311770 [==============================] - 126s 24us/step - loss: 0.7414 - acc: 0.4929 - val_loss: 0.6979 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "5311770/5311770 [==============================] - 126s 24us/step - loss: 0.7413 - acc: 0.4929 - val_loss: 0.6965 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "5311770/5311770 [==============================] - 125s 24us/step - loss: 0.7411 - acc: 0.4929 - val_loss: 0.6952 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "5311770/5311770 [==============================] - 125s 24us/step - loss: 0.7410 - acc: 0.4929 - val_loss: 0.6979 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f213afb1438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_2:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5311770 samples, validate on 51292 samples\n",
      "Epoch 1/10\n",
      "5311770/5311770 [==============================] - 125s 23us/step - loss: 0.7409 - acc: 0.4929 - val_loss: 0.6977 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "5311770/5311770 [==============================] - 125s 24us/step - loss: 0.7409 - acc: 0.4929 - val_loss: 0.6960 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7408 - acc: 0.4929 - val_loss: 0.6957 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7408 - acc: 0.4929 - val_loss: 0.6983 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7407 - acc: 0.4929 - val_loss: 0.6983 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7406 - acc: 0.4929 - val_loss: 0.6972 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7406 - acc: 0.4929 - val_loss: 0.6971 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "5311770/5311770 [==============================] - 124s 23us/step - loss: 0.7405 - acc: 0.4929 - val_loss: 0.6987 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "5311770/5311770 [==============================] - 123s 23us/step - loss: 0.7405 - acc: 0.4929 - val_loss: 0.6965 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "5311770/5311770 [==============================] - 122s 23us/step - loss: 0.7405 - acc: 0.4929 - val_loss: 0.6963 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1e883b3ef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save_weights(\"CNN/CNN_v2/weights/cnn_v2_1_40_1e_4_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.load_weights(\"CNN/CNN_v2/weights/cnn_v2_1_40_1e_4_10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
