{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PJWSTK/s14028/Engine\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import scipy.io as mat\n",
    "\n",
    "from common import *\n",
    "from augmentation import add_pmap\n",
    "from augmentation import augmentation_data\n",
    "from augmentation import augment_data\n",
    "\n",
    "from CNN.CNN_v2_1 import CNN_v2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = mat.loadmat(\"mall_dataset/perspective_roi.mat\")[\"pMapN\"]\n",
    "\n",
    "perspective /= np.min(perspective)\n",
    "perspective = np.round(perspective).astype(np.uint8)\n",
    "\n",
    "train, test = data_sets()\n",
    "image_tensors = train[0], test[0]\n",
    "person_coo_tensors = train[1], test[1]\n",
    "count_matrix = train[2], test[2]\n",
    "\n",
    "image_train, image_test = image_tensors\n",
    "person_coo_train, person_coo_test = person_coo_tensors\n",
    "count_train, count_test = count_matrix\n",
    "count_train = count_train.astype(np.uint16)\n",
    "count_test = count_test.astype(np.uint16)\n",
    "\n",
    "image_train = add_pmap(image_train, perspective)\n",
    "image_test = add_pmap(image_test, perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f37839a29b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v2_1 = CNN_v2_1((480, 640, 4), split_into_parts=20)\n",
    "cnn_v2_1.def_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cnn_v2_1._prepare_images(image_train)\n",
    "anwsers = cnn_v2_1._prepare_anwsers(person_coo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_count = (np.sum(anwsers == 1) * 0.25).astype(np.uint32)\n",
    "zeros_count = (ones_count / 0.25 * 0.75).astype(np.uint32)\n",
    "validation_length = (zeros_count + ones_count).astype(np.int32)\n",
    "\n",
    "val_indices = np.concatenate([np.where(anwsers == 0)[0][:zeros_count],\n",
    "                              np.where(anwsers == 1)[0][:ones_count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = -(images.shape[0] - val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "augmentation = augmentation_data(image_train, anwsers, 20)\n",
    "augmented_data = augment_data(generator, augmentation, images, anwsers)\n",
    "images, anwsers = augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 1\n",
    "\n",
    "images[-validation_length:], images[val_indices] = images[val_indices], images[-validation_length:]\n",
    "anwsers[-validation_length:], anwsers[val_indices] = anwsers[val_indices], anwsers[-validation_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = keras.utils.multi_gpu_model(\n",
    "        cnn_v2_1.model,\n",
    "        gpus=4,\n",
    "        cpu_merge=False)\n",
    "parallel_model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=\"adam\", \n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/10\n",
      "1244460/1244460 [==============================] - 64s 51us/step - loss: 814.4574 - acc: 0.5172 - val_loss: 160.0270 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "1244460/1244460 [==============================] - 55s 44us/step - loss: 156.7554 - acc: 0.5148 - val_loss: 50.4785 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "1244460/1244460 [==============================] - 55s 44us/step - loss: 44.1372 - acc: 0.4977 - val_loss: 29.2118 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "1244460/1244460 [==============================] - 55s 44us/step - loss: 14.3635 - acc: 0.4809 - val_loss: 20.1604 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "1244460/1244460 [==============================] - 53s 42us/step - loss: 6.5756 - acc: 0.4764 - val_loss: 13.2056 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "1244460/1244460 [==============================] - 53s 42us/step - loss: 4.0237 - acc: 0.4751 - val_loss: 9.3994 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 2.8604 - acc: 0.4750 - val_loss: 11.4195 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 2.2166 - acc: 0.4746 - val_loss: 7.0697 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 1.8245 - acc: 0.4746 - val_loss: 3.6856 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 1.5676 - acc: 0.4746 - val_loss: 1.7194 - val_acc: 0.7492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f35801b5fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/10\n",
      "1244460/1244460 [==============================] - 50s 40us/step - loss: 1.3895 - acc: 0.4746 - val_loss: 1.2567 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 1.2614 - acc: 0.4746 - val_loss: 1.1651 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "1244460/1244460 [==============================] - 50s 40us/step - loss: 1.1666 - acc: 0.4746 - val_loss: 1.0929 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "1244460/1244460 [==============================] - 50s 41us/step - loss: 1.0947 - acc: 0.4746 - val_loss: 1.0341 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 1.0392 - acc: 0.4746 - val_loss: 0.9886 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.9954 - acc: 0.4746 - val_loss: 0.9508 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.9603 - acc: 0.4746 - val_loss: 0.9185 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "1244460/1244460 [==============================] - 50s 40us/step - loss: 0.9314 - acc: 0.4746 - val_loss: 0.8945 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.9077 - acc: 0.4746 - val_loss: 0.8720 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.8880 - acc: 0.4746 - val_loss: 0.8537 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3780614e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_1:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.8715 - acc: 0.4746 - val_loss: 0.8389 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.8576 - acc: 0.4746 - val_loss: 0.8247 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.8456 - acc: 0.4746 - val_loss: 0.8127 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "1244460/1244460 [==============================] - 52s 41us/step - loss: 0.8353 - acc: 0.4746 - val_loss: 0.8041 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.8265 - acc: 0.4746 - val_loss: 0.7962 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.8188 - acc: 0.4746 - val_loss: 0.7892 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.8121 - acc: 0.4746 - val_loss: 0.7827 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "1244460/1244460 [==============================] - 52s 41us/step - loss: 0.8062 - acc: 0.4746 - val_loss: 0.7760 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.8010 - acc: 0.4746 - val_loss: 0.7723 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "1244460/1244460 [==============================] - 52s 41us/step - loss: 0.7965 - acc: 0.4746 - val_loss: 0.7665 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f35801b5ef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7925 - acc: 0.4746 - val_loss: 0.7637 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7888 - acc: 0.4746 - val_loss: 0.7589 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7855 - acc: 0.4746 - val_loss: 0.7575 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7826 - acc: 0.4746 - val_loss: 0.7547 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7798 - acc: 0.4746 - val_loss: 0.7512 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7774 - acc: 0.4746 - val_loss: 0.7491 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7751 - acc: 0.4746 - val_loss: 0.7456 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7731 - acc: 0.4746 - val_loss: 0.7440 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "1244460/1244460 [==============================] - 51s 41us/step - loss: 0.7712 - acc: 0.4746 - val_loss: 0.7429 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "1244460/1244460 [==============================] - 52s 42us/step - loss: 0.7695 - acc: 0.4746 - val_loss: 0.7419 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37806146a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=20000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save_weights(\"CNN/CNN_v2/weights/cnn_v2_1_1e_1_30\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
