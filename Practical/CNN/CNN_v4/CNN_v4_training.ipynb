{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PJWSTK/s14028/engineer/Practical\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import scipy.io as mat\n",
    "\n",
    "from common import *\n",
    "from augmentation import add_pmap\n",
    "from augmentation import augmentation_data\n",
    "from augmentation import augment_data\n",
    "\n",
    "from CNN.CNN_v4 import CNN_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = mat.loadmat(\"mall_dataset/perspective_roi.mat\")[\"pMapN\"]\n",
    "\n",
    "perspective /= np.min(perspective)\n",
    "perspective = np.round(perspective).astype(np.uint8)\n",
    "\n",
    "train, test = data_sets()\n",
    "image_tensors = train[0], test[0]\n",
    "person_coo_tensors = train[1], test[1]\n",
    "count_matrix = train[2], test[2]\n",
    "\n",
    "image_train, image_test = image_tensors\n",
    "person_coo_train, person_coo_test = person_coo_tensors\n",
    "count_train, count_test = count_matrix\n",
    "count_train = count_train.astype(np.uint16)\n",
    "count_test = count_test.astype(np.uint16)\n",
    "\n",
    "image_train = add_pmap(image_train, perspective)\n",
    "image_test = add_pmap(image_test, perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f0ae8c41210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v4 = CNN_v4((480, 640, 4), split_into_parts=20)\n",
    "cnn_v4.def_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cnn_v4._prepare_images(image_train)\n",
    "anwsers = cnn_v4._prepare_anwsers(person_coo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_count = (np.sum(anwsers == 1) * 0.25).astype(np.uint32)\n",
    "zeros_count = (ones_count / 0.25 * 0.75).astype(np.uint32)\n",
    "validation_length = (zeros_count + ones_count).astype(np.int32)\n",
    "\n",
    "val_indices = np.concatenate([np.where(anwsers == 0)[0][:zeros_count],\n",
    "                              np.where(anwsers == 1)[0][:ones_count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = -(images.shape[0] - val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "augmentation = augmentation_data(image_train, anwsers, 20)\n",
    "augmented_data = augment_data(generator, augmentation, images, anwsers)\n",
    "images, anwsers = augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 1\n",
    "\n",
    "images[-validation_length:], images[val_indices] = images[val_indices], images[-validation_length:]\n",
    "anwsers[-validation_length:], anwsers[val_indices] = anwsers[val_indices], anwsers[-validation_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = keras.utils.multi_gpu_model(\n",
    "        cnn_v4.model,\n",
    "        gpus=2,\n",
    "        cpu_merge=False)\n",
    "parallel_model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=\"adam\", \n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"CNN/CNN_v4/weights/cnn_v4_1e_6_{}\"\n",
    "\n",
    "class ModelSaver(keras.callbacks.Callback):\n",
    "    __path: str\n",
    "    __current_epoch: int\n",
    "        \n",
    "    def __init__(self, path: str):\n",
    "        self.__path = path\n",
    "        self.__current_epoch = 0\n",
    "        \n",
    "    def on_epoch_end(self, *args, **kwargs):\n",
    "        epoch_path = self.__path.format(self.__current_epoch)\n",
    "        self.__current_epoch += 1\n",
    "        \n",
    "        parallel_model.save_weights(epoch_path)\n",
    "\n",
    "model_saver = ModelSaver(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 125s 101us/step - loss: 53.1809 - accuracy: 0.5336 - val_loss: 24.6635 - val_accuracy: 0.7500\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 114s 92us/step - loss: 29.5678 - accuracy: 0.5682 - val_loss: 19.4019 - val_accuracy: 0.7048\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 114s 92us/step - loss: 21.1116 - accuracy: 0.5838 - val_loss: 15.7836 - val_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 114s 91us/step - loss: 16.3614 - accuracy: 0.5892 - val_loss: 12.7596 - val_accuracy: 0.6295\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 13.1491 - accuracy: 0.5957 - val_loss: 10.4108 - val_accuracy: 0.6252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f0720305cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=10000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 10.7435 - accuracy: 0.6053 - val_loss: 8.5602 - val_accuracy: 0.6146\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 8.8432 - accuracy: 0.6141 - val_loss: 7.0612 - val_accuracy: 0.6173\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 7.3123 - accuracy: 0.6240 - val_loss: 5.8548 - val_accuracy: 0.6185\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 6.0698 - accuracy: 0.6303 - val_loss: 4.8676 - val_accuracy: 0.6138\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 114s 91us/step - loss: 5.0462 - accuracy: 0.6345 - val_loss: 4.0428 - val_accuracy: 0.6012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f072032d510>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=10000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-06>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 113s 90us/step - loss: 4.5839 - accuracy: 0.6370 - val_loss: 4.2508 - val_accuracy: 0.5602\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 4.5753 - accuracy: 0.6364 - val_loss: 4.2607 - val_accuracy: 0.5561\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 113s 91us/step - loss: 4.5660 - accuracy: 0.6368 - val_loss: 4.2543 - val_accuracy: 0.5553\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.5564 - accuracy: 0.6372 - val_loss: 4.2463 - val_accuracy: 0.5552\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.5465 - accuracy: 0.6367 - val_loss: 4.2345 - val_accuracy: 0.5552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f072023e850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=10000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.5354 - accuracy: 0.6373 - val_loss: 4.2262 - val_accuracy: 0.5554\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 113s 90us/step - loss: 4.5245 - accuracy: 0.6370 - val_loss: 4.2139 - val_accuracy: 0.5558\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.5133 - accuracy: 0.6371 - val_loss: 4.2028 - val_accuracy: 0.5553\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.5013 - accuracy: 0.6374 - val_loss: 4.1917 - val_accuracy: 0.5547\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.4892 - accuracy: 0.6371 - val_loss: 4.1802 - val_accuracy: 0.5555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f06d337c810>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=10000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 113s 90us/step - loss: 4.4769 - accuracy: 0.6372 - val_loss: 4.1675 - val_accuracy: 0.5547\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.4642 - accuracy: 0.6367 - val_loss: 4.1549 - val_accuracy: 0.5548\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 113s 90us/step - loss: 4.4509 - accuracy: 0.6369 - val_loss: 4.1443 - val_accuracy: 0.5549\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 113s 90us/step - loss: 4.4373 - accuracy: 0.6368 - val_loss: 4.1352 - val_accuracy: 0.5544\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 4.4235 - accuracy: 0.6367 - val_loss: 4.1189 - val_accuracy: 0.5542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f06d3322b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=10000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 3.8071 - accuracy: 0.6388 - val_loss: 2.7945 - val_accuracy: 0.5905\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 112s 90us/step - loss: 2.8608 - accuracy: 0.6425 - val_loss: 2.1674 - val_accuracy: 0.5828\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 111s 89us/step - loss: 2.2517 - accuracy: 0.6431 - val_loss: 1.7844 - val_accuracy: 0.5716\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 111s 90us/step - loss: 1.8437 - accuracy: 0.6431 - val_loss: 1.5242 - val_accuracy: 0.5584\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 111s 90us/step - loss: 1.5787 - accuracy: 0.6458 - val_loss: 1.3670 - val_accuracy: 0.5362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f06d3177210>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=10000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
