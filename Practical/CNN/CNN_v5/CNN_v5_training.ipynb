{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PJWSTK/s14028/engineer/Practical\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import scipy.io as mat\n",
    "\n",
    "from common import *\n",
    "from augmentation import add_pmap\n",
    "from augmentation import augmentation_data\n",
    "from augmentation import augment_data\n",
    "\n",
    "from CNN.CNN_v5 import CNN_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = mat.loadmat(\"mall_dataset/perspective_roi.mat\")[\"pMapN\"]\n",
    "\n",
    "perspective /= np.min(perspective)\n",
    "perspective = np.round(perspective).astype(np.uint8)\n",
    "\n",
    "train, test = data_sets()\n",
    "image_tensors = train[0], test[0]\n",
    "person_coo_tensors = train[1], test[1]\n",
    "count_matrix = train[2], test[2]\n",
    "\n",
    "image_train, image_test = image_tensors\n",
    "person_coo_train, person_coo_test = person_coo_tensors\n",
    "count_train, count_test = count_matrix\n",
    "count_train = count_train.astype(np.uint16)\n",
    "count_test = count_test.astype(np.uint16)\n",
    "\n",
    "image_train = add_pmap(image_train, perspective)\n",
    "image_test = add_pmap(image_test, perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f541687a8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v5 = CNN_v5((480, 640, 4), split_into_parts=20)\n",
    "cnn_v5.def_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cnn_v5._prepare_images(image_train)\n",
    "anwsers = cnn_v5._prepare_anwsers(person_coo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_count = (np.sum(anwsers == 1) * 0.25).astype(np.uint32)\n",
    "zeros_count = (ones_count / 0.25 * 0.75).astype(np.uint32)\n",
    "validation_length = (zeros_count + ones_count).astype(np.int32)\n",
    "\n",
    "val_indices = np.concatenate([np.where(anwsers == 0)[0][:zeros_count],\n",
    "                              np.where(anwsers == 1)[0][:ones_count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = -(images.shape[0] - val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "augmentation = augmentation_data(image_train, anwsers, 20)\n",
    "augmented_data = augment_data(generator, augmentation, images, anwsers)\n",
    "images, anwsers = augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 1\n",
    "\n",
    "images[-validation_length:], images[val_indices] = images[val_indices], images[-validation_length:]\n",
    "anwsers[-validation_length:], anwsers[val_indices] = anwsers[val_indices], anwsers[-validation_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = keras.utils.multi_gpu_model(\n",
    "        cnn_v5.model,\n",
    "        gpus=2,\n",
    "        cpu_merge=False)\n",
    "parallel_model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=\"adam\", \n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"CNN/CNN_v5/weights/cnn_v5_1e_6_{}\"\n",
    "\n",
    "class ModelSaver(keras.callbacks.Callback):\n",
    "    __path: str\n",
    "    __current_epoch: int\n",
    "        \n",
    "    def __init__(self, path: str, epoch: int = 0):\n",
    "        self.__path = path\n",
    "        self.__current_epoch = epoch\n",
    "        \n",
    "    def on_epoch_end(self, *args, **kwargs):\n",
    "        epoch_path = self.__path.format(self.__current_epoch)\n",
    "        self.__current_epoch += 1\n",
    "        \n",
    "        parallel_model.save_weights(epoch_path)\n",
    "\n",
    "model_saver = ModelSaver(path, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 336s 270us/step - loss: 23.7739 - accuracy: 0.8681 - val_loss: 7.9590 - val_accuracy: 0.8246\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 328s 264us/step - loss: 6.6932 - accuracy: 0.9337 - val_loss: 4.2192 - val_accuracy: 0.8666\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 328s 263us/step - loss: 3.0700 - accuracy: 0.9417 - val_loss: 2.0931 - val_accuracy: 0.8803\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 328s 263us/step - loss: 1.5082 - accuracy: 0.9418 - val_loss: 1.1252 - val_accuracy: 0.8830\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 327s 263us/step - loss: 0.7879 - accuracy: 0.9399 - val_loss: 0.6725 - val_accuracy: 0.8827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fcf6c1bbe90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=5000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-05>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/10\n",
      "1244460/1244460 [==============================] - 339s 272us/step - loss: 62.4959 - accuracy: 0.7317 - val_loss: 34.5997 - val_accuracy: 0.8678\n",
      "Epoch 2/10\n",
      "1244460/1244460 [==============================] - 332s 267us/step - loss: 35.9286 - accuracy: 0.8274 - val_loss: 29.0350 - val_accuracy: 0.8785\n",
      "Epoch 3/10\n",
      "1244460/1244460 [==============================] - 334s 268us/step - loss: 26.5039 - accuracy: 0.8623 - val_loss: 22.8120 - val_accuracy: 0.8828\n",
      "Epoch 4/10\n",
      "1244460/1244460 [==============================] - 333s 267us/step - loss: 21.3654 - accuracy: 0.8828 - val_loss: 18.8705 - val_accuracy: 0.8827\n",
      "Epoch 5/10\n",
      "1244460/1244460 [==============================] - 332s 267us/step - loss: 17.9188 - accuracy: 0.8970 - val_loss: 16.0932 - val_accuracy: 0.8805\n",
      "Epoch 6/10\n",
      "1244460/1244460 [==============================] - 332s 267us/step - loss: 15.3512 - accuracy: 0.9076 - val_loss: 13.9236 - val_accuracy: 0.8793\n",
      "Epoch 7/10\n",
      "1244460/1244460 [==============================] - 332s 267us/step - loss: 13.3036 - accuracy: 0.9157 - val_loss: 12.1510 - val_accuracy: 0.8768\n",
      "Epoch 8/10\n",
      "1244460/1244460 [==============================] - 333s 267us/step - loss: 11.6004 - accuracy: 0.9218 - val_loss: 10.6536 - val_accuracy: 0.8759\n",
      "Epoch 9/10\n",
      "1244460/1244460 [==============================] - 333s 268us/step - loss: 10.1539 - accuracy: 0.9263 - val_loss: 9.3770 - val_accuracy: 0.8742\n",
      "Epoch 10/10\n",
      "1244460/1244460 [==============================] - 333s 268us/step - loss: 8.9100 - accuracy: 0.9302 - val_loss: 8.2792 - val_accuracy: 0.8733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f52741f2fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=5000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
