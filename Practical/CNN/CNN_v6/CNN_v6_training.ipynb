{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/PJWSTK/s14028/engineer/Practical\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import scipy.io as mat\n",
    "\n",
    "from common import *\n",
    "from augmentation import add_pmap\n",
    "from augmentation import augmentation_data\n",
    "from augmentation import augment_data\n",
    "\n",
    "from CNN.CNN_v6 import CNN_v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = mat.loadmat(\"mall_dataset/perspective_roi.mat\")[\"pMapN\"]\n",
    "\n",
    "perspective /= np.min(perspective)\n",
    "perspective = np.round(perspective).astype(np.uint8)\n",
    "\n",
    "train, test = data_sets()\n",
    "image_tensors = train[0], test[0]\n",
    "person_coo_tensors = train[1], test[1]\n",
    "count_matrix = train[2], test[2]\n",
    "\n",
    "image_train, image_test = image_tensors\n",
    "person_coo_train, person_coo_test = person_coo_tensors\n",
    "count_train, count_test = count_matrix\n",
    "count_train = count_train.astype(np.uint16)\n",
    "count_test = count_test.astype(np.uint16)\n",
    "\n",
    "image_train = add_pmap(image_train, perspective)\n",
    "image_test = add_pmap(image_test, perspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fb581957810>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v6 = CNN_v6((480, 640, 4), split_into_parts=20)\n",
    "cnn_v6.def_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cnn_v6._prepare_images(image_train)\n",
    "anwsers = cnn_v6._prepare_anwsers(person_coo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_count = (np.sum(anwsers == 1) * 0.25).astype(np.uint32)\n",
    "zeros_count = (ones_count / 0.25 * 0.75).astype(np.uint32)\n",
    "validation_length = (zeros_count + ones_count).astype(np.int32)\n",
    "\n",
    "val_indices = np.concatenate([np.where(anwsers == 0)[0][:zeros_count],\n",
    "                              np.where(anwsers == 1)[0][:ones_count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = -(images.shape[0] - val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.preprocessing.image.ImageDataGenerator(rotation_range=20)\n",
    "\n",
    "augmentation = augmentation_data(image_train, anwsers, 20)\n",
    "augmented_data = augment_data(generator, augmentation, images, anwsers)\n",
    "images, anwsers = augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsers[val_indices[zeros_count:]] = 1\n",
    "\n",
    "images[-validation_length:], images[val_indices] = images[val_indices], images[-validation_length:]\n",
    "anwsers[-validation_length:], anwsers[val_indices] = anwsers[val_indices], anwsers[-validation_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = keras.utils.multi_gpu_model(\n",
    "        cnn_v6.model,\n",
    "        gpus=2,\n",
    "        cpu_merge=False)\n",
    "parallel_model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=\"adam\", \n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"CNN/CNN_v6/weights/cnn_v6_1e_6_{}\"\n",
    "\n",
    "class ModelSaver(keras.callbacks.Callback):\n",
    "    __path: str\n",
    "    __current_epoch: int\n",
    "        \n",
    "    def __init__(self, path: str, epoch: int = 0):\n",
    "        self.__path = path\n",
    "        self.__current_epoch = epoch\n",
    "        \n",
    "    def on_epoch_end(self, *args, **kwargs):\n",
    "        epoch_path = self.__path.format(self.__current_epoch)\n",
    "        self.__current_epoch += 1\n",
    "        \n",
    "        parallel_model.save_weights(epoch_path)\n",
    "\n",
    "model_saver = ModelSaver(path, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/5\n",
      "1244460/1244460 [==============================] - 346s 278us/step - loss: 249.7452 - accuracy: 0.8236 - val_loss: 77.3207 - val_accuracy: 0.8438\n",
      "Epoch 2/5\n",
      "1244460/1244460 [==============================] - 339s 272us/step - loss: 65.8641 - accuracy: 0.8977 - val_loss: 38.5176 - val_accuracy: 0.8481\n",
      "Epoch 3/5\n",
      "1244460/1244460 [==============================] - 338s 271us/step - loss: 28.1668 - accuracy: 0.8982 - val_loss: 17.5020 - val_accuracy: 0.8533\n",
      "Epoch 4/5\n",
      "1244460/1244460 [==============================] - 337s 270us/step - loss: 12.8268 - accuracy: 0.8929 - val_loss: 8.2077 - val_accuracy: 0.8522\n",
      "Epoch 5/5\n",
      "1244460/1244460 [==============================] - 335s 269us/step - loss: 5.8596 - accuracy: 0.8843 - val_loss: 3.8361 - val_accuracy: 0.8497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f74cc43a490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=5000, epochs=5,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.optimizer.lr.assign(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1244460 samples, validate on 46216 samples\n",
      "Epoch 1/10\n",
      "1244460/1244460 [==============================] - 346s 278us/step - loss: 242.9190 - accuracy: 0.8206 - val_loss: 78.3556 - val_accuracy: 0.6528\n",
      "Epoch 2/10\n",
      "1244460/1244460 [==============================] - 343s 275us/step - loss: 65.7822 - accuracy: 0.8951 - val_loss: 40.1079 - val_accuracy: 0.8533\n",
      "Epoch 3/10\n",
      "1244460/1244460 [==============================] - 338s 272us/step - loss: 29.6050 - accuracy: 0.8980 - val_loss: 18.9682 - val_accuracy: 0.8562\n",
      "Epoch 4/10\n",
      "1244460/1244460 [==============================] - 339s 272us/step - loss: 13.7836 - accuracy: 0.8952 - val_loss: 8.6607 - val_accuracy: 0.8629\n",
      "Epoch 5/10\n",
      "1244460/1244460 [==============================] - 337s 270us/step - loss: 6.2930 - accuracy: 0.8912 - val_loss: 3.9919 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "1244460/1244460 [==============================] - 337s 271us/step - loss: 2.9797 - accuracy: 0.8905 - val_loss: 2.3374 - val_accuracy: 0.8731\n",
      "Epoch 7/10\n",
      "1244460/1244460 [==============================] - 336s 270us/step - loss: 1.8970 - accuracy: 0.9004 - val_loss: 1.6630 - val_accuracy: 0.8782\n",
      "Epoch 8/10\n",
      "1244460/1244460 [==============================] - 334s 268us/step - loss: 1.3988 - accuracy: 0.9054 - val_loss: 1.2838 - val_accuracy: 0.8794\n",
      "Epoch 9/10\n",
      "1244460/1244460 [==============================] - 334s 268us/step - loss: 1.1020 - accuracy: 0.9076 - val_loss: 1.0439 - val_accuracy: 0.8803\n",
      "Epoch 10/10\n",
      "1244460/1244460 [==============================] - 335s 269us/step - loss: 0.9060 - accuracy: 0.9086 - val_loss: 0.8818 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb3cc6001d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit(images[:-validation_length], anwsers[:-validation_length], batch_size=5000, epochs=10,\n",
    "                   validation_data=(images[-validation_length:], anwsers[-validation_length:]),\n",
    "                   callbacks=[model_saver])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
